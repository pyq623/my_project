{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b977d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"\"\"\n",
    "无法解析LLM响应为JSON: 根据给定的搜索空间和约束条件，我设计了一个新的TinyML模型架构，以满足约束并优化准确率和计算量。以下是模型架构配置的JSON格式：\n",
    "```json\n",
    "{\n",
    "    \"stages\": [\n",
    "        {\n",
    "            \"blocks\": [\n",
    "                {\n",
    "                    \"type\": \"DWSepConv\",\n",
    "                    \"kernel_size\": 3,\n",
    "                    \"stride\": 1,\n",
    "                    \"expansion\": 4,\n",
    "                    \"activation\": \"ReLU6\",\n",
    "                    \"has_se\": false,\n",
    "                    \"skip_connection\": true\n",
    "                }\n",
    "            ],\n",
    "            \"channels\": 16\n",
    "        },\n",
    "        {\n",
    "            \"blocks\": [\n",
    "                {\n",
    "                    \"type\": \"MBConv\",\n",
    "                    \"kernel_size\": 5,\n",
    "                    \"stride\": 2,\n",
    "                    \"expansion\": 6,\n",
    "                    \"activation\": \"Swish\",\n",
    "                    \"has_se\": true,\n",
    "                    \"skip_connection\": true\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"MBConv\",\n",
    "                    \"kernel_size\": 5,\n",
    "                    \"stride\": 1,\n",
    "                    \"expansion\": 4,\n",
    "                    \"activation\": \"LeakyReLU\",\n",
    "                    \"has_se\": false,\n",
    "                    \"skip_connection\": true\n",
    "                }\n",
    "            ],\n",
    "            \"channels\": 24\n",
    "        },\n",
    "        {\n",
    "            \"blocks\": [\n",
    "                {\n",
    "                    \"type\": \"MBConv\",\n",
    "                    \"kernel_size\": 3,\n",
    "                    \"stride\": 2,\n",
    "                    \"expansion\": 3,\n",
    "                    \"activation\": \"ReLU6\",\n",
    "                    \"has_se\": true,\n",
    "                    \"skip_connection\": true\n",
    "                }\n",
    "            ],\n",
    "            \"channels\": 32\n",
    "        },\n",
    "        {\n",
    "            \"blocks\": [\n",
    "                {\n",
    "                    \"type\": \"DWSepConv\",\n",
    "                    \"kernel_size\": 7,\n",
    "                    \"stride\": 1,\n",
    "                    \"expansion\": 6,\n",
    "                    \"activation\": \"Swish\",\n",
    "                    \"has_se\": false,\n",
    "                    \"skip_connection\": true\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"MBConv\",\n",
    "                    \"kernel_size\": 5,\n",
    "                    \"stride\": 1,\n",
    "                    \"expansion\": 4,\n",
    "                    \"activation\": \"LeakyReLU\",\n",
    "                    \"has_se\": true,\n",
    "                    \"skip_connection\": false\n",
    "                }\n",
    "            ],\n",
    "            \"channels\": 48\n",
    "        },\n",
    "        {\n",
    "            \"blocks\": [\n",
    "                {\n",
    "                    \"type\": \"MBConv\",\n",
    "                    \"kernel_size\": 3,\n",
    "                    \"stride\": 1,\n",
    "                    \"expansion\": 6,\n",
    "                    \"activation\": \"ReLU6\",\n",
    "                    \"has_se\": true,\n",
    "                    \"skip_connection\": true\n",
    "                }\n",
    "            ],\n",
    "            \"channels\": 64\n",
    "        }\n",
    "    ],\n",
    "    \"constraints\": {\n",
    "        \"max_sram\": 312.5,\n",
    "        \"min_macs\": 70.0,\n",
    "        \"max_macs\": 350.0,\n",
    "        \"max_params\": 1.0\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c99376ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的JSON字符串:\n",
      "{\n",
      "    \"stages\": [\n",
      "        {\n",
      "            \"blocks\": [\n",
      "                {\n",
      "                    \"type\": \"DWSepConv\",\n",
      "                    \"kernel_size\": 3,\n",
      "                    \"stride\": 1,\n",
      "                    \"expansion\": 4,\n",
      "                    \"activation\": \"ReLU6\",\n",
      "                    \"has_se\": false,\n",
      "                    \"skip_connection\": true\n",
      "                }\n",
      "            ],\n",
      "            \"channels\": 16\n",
      "        },\n",
      "        {\n",
      "            \"blocks\": [\n",
      "                {\n",
      "                    \"type\": \"MBConv\",\n",
      "                    \"kernel_size\": 5,\n",
      "                    \"stride\": 2,\n",
      "                    \"expansion\": 6,\n",
      "                    \"activation\": \"Swish\",\n",
      "                    \"has_se\": true,\n",
      "                    \"skip_connection\": true\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"MBConv\",\n",
      "                    \"kernel_size\": 5,\n",
      "                    \"stride\": 1,\n",
      "                    \"expansion\": 4,\n",
      "                    \"activation\": \"LeakyReLU\",\n",
      "                    \"has_se\": false,\n",
      "                    \"skip_connection\": true\n",
      "                }\n",
      "            ],\n",
      "            \"channels\": 24\n",
      "        },\n",
      "        {\n",
      "            \"blocks\": [\n",
      "                {\n",
      "                    \"type\": \"MBConv\",\n",
      "                    \"kernel_size\": 3,\n",
      "                    \"stride\": 2,\n",
      "                    \"expansion\": 3,\n",
      "                    \"activation\": \"ReLU6\",\n",
      "                    \"has_se\": true,\n",
      "                    \"skip_connection\": true\n",
      "                }\n",
      "            ],\n",
      "            \"channels\": 32\n",
      "        },\n",
      "        {\n",
      "            \"blocks\": [\n",
      "                {\n",
      "                    \"type\": \"DWSepConv\",\n",
      "                    \"kernel_size\": 7,\n",
      "                    \"stride\": 1,\n",
      "                    \"expansion\": 6,\n",
      "                    \"activation\": \"Swish\",\n",
      "                    \"has_se\": false,\n",
      "                    \"skip_connection\": true\n",
      "                },\n",
      "                {\n",
      "                    \"type\": \"MBConv\",\n",
      "                    \"kernel_size\": 5,\n",
      "                    \"stride\": 1,\n",
      "                    \"expansion\": 4,\n",
      "                    \"activation\": \"LeakyReLU\",\n",
      "                    \"has_se\": true,\n",
      "                    \"skip_connection\": false\n",
      "                }\n",
      "            ],\n",
      "            \"channels\": 48\n",
      "        },\n",
      "        {\n",
      "            \"blocks\": [\n",
      "                {\n",
      "                    \"type\": \"MBConv\",\n",
      "                    \"kernel_size\": 3,\n",
      "                    \"stride\": 1,\n",
      "                    \"expansion\": 6,\n",
      "                    \"activation\": \"ReLU6\",\n",
      "                    \"has_se\": true,\n",
      "                    \"skip_connection\": true\n",
      "                }\n",
      "            ],\n",
      "            \"channels\": 64\n",
      "        }\n",
      "    ],\n",
      "    \"constraints\": {\n",
      "        \"max_sram\": 312.5,\n",
      "        \"min_macs\": 70.0,\n",
      "        \"max_macs\": 350.0,\n",
      "        \"max_params\": 1.0\n",
      "    }\n",
      "}\n",
      "{'stages': [{'blocks': [{'type': 'DWSepConv', 'kernel_size': 3, 'stride': 1, 'expansion': 4, 'activation': 'ReLU6', 'has_se': False, 'skip_connection': True}], 'channels': 16}, {'blocks': [{'type': 'MBConv', 'kernel_size': 5, 'stride': 2, 'expansion': 6, 'activation': 'Swish', 'has_se': True, 'skip_connection': True}, {'type': 'MBConv', 'kernel_size': 5, 'stride': 1, 'expansion': 4, 'activation': 'LeakyReLU', 'has_se': False, 'skip_connection': True}], 'channels': 24}, {'blocks': [{'type': 'MBConv', 'kernel_size': 3, 'stride': 2, 'expansion': 3, 'activation': 'ReLU6', 'has_se': True, 'skip_connection': True}], 'channels': 32}, {'blocks': [{'type': 'DWSepConv', 'kernel_size': 7, 'stride': 1, 'expansion': 6, 'activation': 'Swish', 'has_se': False, 'skip_connection': True}, {'type': 'MBConv', 'kernel_size': 5, 'stride': 1, 'expansion': 4, 'activation': 'LeakyReLU', 'has_se': True, 'skip_connection': False}], 'channels': 48}, {'blocks': [{'type': 'MBConv', 'kernel_size': 3, 'stride': 1, 'expansion': 6, 'activation': 'ReLU6', 'has_se': True, 'skip_connection': True}], 'channels': 64}], 'constraints': {'max_sram': 312.5, 'min_macs': 70.0, 'max_macs': 350.0, 'max_params': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "# config = json.loads(response.strip())\n",
    "# print(f\"解析出的配置:\\n{json.dumps(config, indent=2)}\")\n",
    "# 方法2: 处理```json标记的情况\n",
    "json_match = re.search(r'```json(.*?)```', response, re.DOTALL)\n",
    "if json_match:\n",
    "    json_str = json_match.group(1).strip()\n",
    "    print(f\"提取的JSON字符串:\\n{json_str}\")\n",
    "    print(json.loads(json_str)) \n",
    "# 基本配置验证\n",
    "# if not all(k in config for k in ['stages', 'constraints']):\n",
    "#     raise ValueError(\"配置缺少必要字段(stages 或 constraints)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acadddba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     arch_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 提取前50个最佳架构及其准确率\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m top_archs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43march_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[:\u001b[38;5;241m50\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m (\n\u001b[1;32m     13\u001b[0m     [arch[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m top_archs],\n\u001b[1;32m     14\u001b[0m     [arch[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m top_archs]\n\u001b[1;32m     15\u001b[0m )\n",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     arch_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 提取前50个最佳架构及其准确率\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m top_archs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(arch_data\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:\u001b[38;5;241m50\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m (\n\u001b[1;32m     13\u001b[0m     [arch[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m top_archs],\n\u001b[1;32m     14\u001b[0m     [arch[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m top_archs]\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "\n",
    "with open('/root/tinyml/tnas_background/nasbench201_cifar10.json', 'r') as f:\n",
    "    arch_data = json.load(f)\n",
    "\n",
    "# 提取前50个最佳架构及其准确率\n",
    "top_archs = sorted(arch_data.items(), key=lambda x: x[1]['accuracy'], reverse=True)[:50]\n",
    "print (\n",
    "    [arch[1]['config'] for arch in top_archs],\n",
    "    [arch[1]['accuracy'] for arch in top_archs]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b63e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: |nor_conv_1x1~0|+|skip_connect~0|avg_pool_3x3~1|+|nor_conv_1x1~0|none~1|nor_conv_1x1~2|, Value: {'val_acc_200': 87.72799999267578, 'test_acc_200': 90.34, 'rank': 8163}\n",
      "Key: |avg_pool_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|none~0|nor_conv_3x3~1|nor_conv_3x3~2|, Value: {'val_acc_200': 88.366, 'test_acc_200': 91.815, 'rank': 5600}\n",
      "Key: |skip_connect~0|+|none~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|avg_pool_3x3~2|, Value: {'val_acc_200': 88.93866665608725, 'test_acc_200': 92.02666666666666, 'rank': 4720}\n",
      "Top 50 architectures (val_acc_200):\n",
      "[91.60666665039064, 91.56800001220704, 91.5533333235677, 91.55199997558594, 91.54399997314454, 91.53333331461589, 91.51599999023438, 91.50533331298827, 91.49599997884116, 91.44799998860678, 91.43999998453775, 91.42399998779297, 91.42266665120444, 91.41999999023437, 91.41999998535157, 91.41800000122069, 91.38999999023437, 91.37799998168944, 91.36533333251953, 91.35999999267578, 91.35999997802735, 91.356, 91.35066664876302, 91.34799999755859, 91.34399999267578, 91.34399997314453, 91.33999998291016, 91.33799998168945, 91.33599998535158, 91.33599998535156, 91.33399998291014, 91.32799998413086, 91.32399998209637, 91.31399999511719, 91.29799999023437, 91.29599998209636, 91.28799998901367, 91.28399999511718, 91.27599999511719, 91.25999998901366, 91.25199999511719, 91.23799998779296, 91.23733331868489, 91.22999998901366, 91.2199999991862, 91.21999998046876, 91.21199999023437, 91.20199998901367, 91.18799997924805, 91.15999999430339]\n",
      "['|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|avg_pool_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|avg_pool_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|skip_connect~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|skip_connect~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|skip_connect~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|skip_connect~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "with open('/root/tinyml/tnas_background/nasbench201_cifar10.json', 'r') as f:\n",
    "    arch_data = json.load(f)\n",
    "\n",
    "# 打印前5个条目，看看结构\n",
    "for i, (k, v) in enumerate(arch_data.items()):\n",
    "    if i >= 3:  # 只打印前5个\n",
    "        break\n",
    "    print(f\"Key: {k}, Value: {v}\")\n",
    "\n",
    "top_archs = sorted(arch_data.items(), key=lambda x: x[1]['val_acc_200'], reverse=True)[:50]\n",
    "print(\"Top 50 architectures (val_acc_200):\")\n",
    "print([arch[1]['val_acc_200'] for arch in top_archs])\n",
    "print([arch[0] for arch in top_archs])  # 打印架构字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e9131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: |nor_conv_1x1~0|+|skip_connect~0|avg_pool_3x3~1|+|nor_conv_1x1~0|none~1|nor_conv_1x1~2|, Value: {'val_acc_200': 65.4400000366211, 'test_acc_200': 65.84, 'rank': 7122}\n",
      "Key: |avg_pool_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|none~0|nor_conv_3x3~1|nor_conv_3x3~2|, Value: {'val_acc_200': 68.85000002746582, 'test_acc_200': 69.01000000610351, 'rank': 2261}\n",
      "Key: |skip_connect~0|+|none~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|avg_pool_3x3~2|, Value: {'val_acc_200': 66.76000000406901, 'test_acc_200': 67.01999997558595, 'rank': 5847}\n",
      "Top 50 architectures (val_acc_200):\n",
      "[73.4933333577474, 73.30666659749348, 73.12666664632162, 73.08666667073568, 73.01999998779297, 72.98000002441407, 72.9599999206543, 72.94666666666666, 72.85999995727539, 72.77333328857422, 72.74666660563152, 72.73999994710286, 72.72000003662109, 72.71999991455078, 72.6399999226888, 72.59333336181642, 72.59333321940103, 72.52999996337891, 72.51999997558593, 72.51999990844726, 72.51333331298828, 72.51333330078126, 72.4799999633789, 72.43333326416017, 72.41999991455077, 72.39999986572266, 72.38999993896485, 72.37000003051757, 72.35333328043619, 72.34999996948243, 72.29999994506836, 72.29000000610353, 72.26666670328775, 72.21333327636718, 72.17999989420572, 72.16999995117187, 72.16666661376954, 72.15999997151692, 72.15999987792969, 72.14999989013671, 72.11333330891927, 72.01999995727539, 72.00999989624023, 71.99000002441406, 71.97333326009114, 71.95999998168945, 71.93999997558593, 71.9399998779297, 71.93999986572265, 71.92666660970052]\n",
      "['|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|avg_pool_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|none~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|avg_pool_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|none~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|nor_conv_1x1~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|none~1|nor_conv_3x3~2|']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "with open('/root/tinyml/tnas_background/nasbench201_cifar100.json', 'r') as f:\n",
    "    arch_data = json.load(f)\n",
    "\n",
    "# 打印前5个条目，看看结构\n",
    "for i, (k, v) in enumerate(arch_data.items()):\n",
    "    if i >= 3:  # 只打印前5个\n",
    "        break\n",
    "    print(f\"Key: {k}, Value: {v}\")\n",
    "\n",
    "top_archs = sorted(arch_data.items(), key=lambda x: x[1]['val_acc_200'], reverse=True)[:50]\n",
    "print(\"Top 50 architectures (val_acc_200):\")\n",
    "print([arch[1]['val_acc_200'] for arch in top_archs])\n",
    "print([arch[0] for arch in top_archs])  # 打印架构字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16794a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: |nor_conv_1x1~0|+|skip_connect~0|avg_pool_3x3~1|+|nor_conv_1x1~0|none~1|nor_conv_1x1~2|, Value: {'val_acc_200': 38.033333302815755, 'test_acc_200': 38.73333321126302, 'rank': 5802}\n",
      "Key: |avg_pool_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|none~0|nor_conv_3x3~1|nor_conv_3x3~2|, Value: {'val_acc_200': 31.966666610717773, 'test_acc_200': 31.54999994913737, 'rank': 11108}\n",
      "Key: |skip_connect~0|+|none~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|avg_pool_3x3~2|, Value: {'val_acc_200': 40.0111110534668, 'test_acc_200': 40.1111109890408, 'rank': 3960}\n",
      "Top 50 architectures (val_acc_200):\n",
      "[46.73333327229818, 46.5555554945204, 46.5166666615804, 46.49999995422363, 46.49999991861979, 46.48888883463542, 46.46666666666667, 46.44999995930989, 46.39999984741211, 46.37777776082356, 46.36666665649414, 46.36666664632162, 46.34999992370605, 46.32222212727864, 46.31666653442383, 46.26666663614909, 46.23333331298828, 46.22222220187717, 46.21666658528646, 46.20000003051758, 46.183333302815754, 46.183333206176755, 46.13333323160808, 46.08888888549805, 46.0666665242513, 46.05555541314019, 46.033333302815755, 46.03333323669433, 46.01666668701172, 45.999999994913736, 45.98888881429036, 45.983333307902015, 45.96666672770182, 45.96666654459636, 45.955555562337246, 45.933333257039386, 45.91111107042101, 45.911111033121735, 45.90000001525879, 45.88333325703938, 45.866666564941404, 45.79999985758464, 45.76666661241319, 45.75000001525879, 45.749999933878584, 45.73333335367838, 45.7333332417806, 45.7166665802002, 45.70000003051758, 45.70000003051758]\n",
      "['|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|none~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|skip_connect~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|skip_connect~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|skip_connect~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|avg_pool_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|nor_conv_1x1~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|avg_pool_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|avg_pool_3x3~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|avg_pool_3x3~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_1x1~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|none~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|skip_connect~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|avg_pool_3x3~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_1x1~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_3x3~0|none~1|skip_connect~2|', '|nor_conv_3x3~0|+|skip_connect~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_1x1~1|nor_conv_1x1~2|', '|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_1x1~1|+|nor_conv_1x1~0|skip_connect~1|nor_conv_3x3~2|', '|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2|']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "with open('/root/tinyml/tnas_background/nasbench201_imagenet.json', 'r') as f:\n",
    "    arch_data = json.load(f)\n",
    "\n",
    "# 打印前5个条目，看看结构\n",
    "for i, (k, v) in enumerate(arch_data.items()):\n",
    "    if i >= 3:  # 只打印前5个\n",
    "        break\n",
    "    print(f\"Key: {k}, Value: {v}\")\n",
    "\n",
    "top_archs = sorted(arch_data.items(), key=lambda x: x[1]['val_acc_200'], reverse=True)[:50]\n",
    "print(\"Top 50 architectures (val_acc_200):\")\n",
    "print([arch[1]['val_acc_200'] for arch in top_archs])\n",
    "print([arch[0] for arch in top_archs])  # 打印架构字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd7eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 03:07:33,856 - __main__ - INFO - \n",
      "测试数据 - 前5个架构字符串和准确率:\n",
      "2025-07-20 03:07:33,859 - __main__ - INFO - 1. |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2| -> 46.73333327229818\n",
      "2025-07-20 03:07:33,860 - __main__ - INFO - 2. |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2| -> 46.5555554945204\n",
      "2025-07-20 03:07:33,860 - __main__ - INFO - 3. |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|none~1|nor_conv_3x3~2| -> 46.5166666615804\n",
      "2025-07-20 03:07:33,860 - __main__ - INFO - 4. |nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2| -> 46.49999995422363\n",
      "2025-07-20 03:07:33,861 - __main__ - INFO - 5. |nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2| -> 46.49999991861979\n",
      "2025-07-20 03:07:33,861 - __main__ - INFO - 从 /root/tinyml/tnas_background/nasbench201_imagenet.json 加载了 5 个架构\n",
      "2025-07-20 03:07:33,891 - __main__ - INFO - \n",
      "测试数据 - 前5个架构字符串和准确率:\n",
      "2025-07-20 03:07:33,892 - __main__ - INFO - 1. |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2| -> 46.73333327229818\n",
      "2025-07-20 03:07:33,892 - __main__ - INFO - 2. |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2| -> 46.5555554945204\n",
      "2025-07-20 03:07:33,892 - __main__ - INFO - 3. |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|none~1|nor_conv_3x3~2| -> 46.5166666615804\n",
      "2025-07-20 03:07:33,893 - __main__ - INFO - 4. |nor_conv_3x3~0|+|none~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2| -> 46.49999995422363\n",
      "2025-07-20 03:07:33,893 - __main__ - INFO - 5. |nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_1x1~2| -> 46.49999991861979\n",
      "2025-07-20 03:07:33,893 - __main__ - INFO - 从 /root/tinyml/tnas_background/nasbench201_imagenet.json 加载了 5 个架构\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "开始测试 NASBench201 加载器\n",
      "==================================================\n",
      "\n",
      "测试单个架构解析: |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "解析结果:\n",
      "{'stages': {'0': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_3x3'}]},\n",
      "            '1': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_1x1'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_1x1'}]},\n",
      "            '2': {'blocks': [{'node_idx': 0, 'type': 'skip_connect'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_3x3'},\n",
      "                             {'node_idx': 2, 'type': 'nor_conv_3x3'}]}}}\n",
      "\n",
      "测试加载函数...\n",
      "\n",
      "加载结果概要:\n",
      "加载的架构数量: 5\n",
      "加载的性能指标数量: 5\n",
      "\n",
      "第一个架构的详细信息和性能:\n",
      "准确率: 46.73333327229818\n",
      "架构配置:\n",
      "{'stages': {'0': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_3x3'}]},\n",
      "            '1': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_1x1'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_1x1'}]},\n",
      "            '2': {'blocks': [{'node_idx': 0, 'type': 'skip_connect'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_3x3'},\n",
      "                             {'node_idx': 2, 'type': 'nor_conv_3x3'}]}}}\n",
      "\n",
      "所有架构的性能指标:\n",
      "[46.73333327229818, 46.5555554945204, 46.5166666615804, 46.49999995422363, 46.49999991861979]\n",
      "==================================================\n",
      "开始测试 NASBench201 加载器\n",
      "==================================================\n",
      "\n",
      "测试单个架构解析: |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "解析结果:\n",
      "{'stages': {'0': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_3x3'}]},\n",
      "            '1': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_1x1'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_1x1'}]},\n",
      "            '2': {'blocks': [{'node_idx': 0, 'type': 'skip_connect'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_3x3'},\n",
      "                             {'node_idx': 2, 'type': 'nor_conv_3x3'}]}}}\n",
      "\n",
      "测试加载函数...\n",
      "\n",
      "加载结果概要:\n",
      "加载的架构数量: 5\n",
      "加载的性能指标数量: 5\n",
      "\n",
      "第一个架构的详细信息和性能:\n",
      "准确率: 46.73333327229818\n",
      "架构配置:\n",
      "{'stages': {'0': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_3x3'}]},\n",
      "            '1': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_1x1'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_1x1'}]},\n",
      "            '2': {'blocks': [{'node_idx': 0, 'type': 'skip_connect'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_3x3'},\n",
      "                             {'node_idx': 2, 'type': 'nor_conv_3x3'}]}}}\n",
      "\n",
      "所有架构的性能指标:\n",
      "[46.73333327229818, 46.5555554945204, 46.5166666615804, 46.49999995422363, 46.49999991861979]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NASBench201Loader:\n",
    "    def _load_initial_architectures(self) -> Tuple[List[Dict], List[float]]:\n",
    "        \"\"\"测试用简化版本，只加载一个文件\"\"\"\n",
    "        dataset_files = [\n",
    "            '/root/tinyml/tnas_background/nasbench201_imagenet.json'  # 只测试一个文件\n",
    "        ]\n",
    "        \n",
    "        all_archs = []\n",
    "        all_perfs = []\n",
    "        \n",
    "        for file_path in dataset_files:\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    arch_data = json.load(f)\n",
    "                \n",
    "                # 只取前5个用于测试\n",
    "                top_archs = sorted(arch_data.items(), \n",
    "                                 key=lambda x: x[1]['val_acc_200'], \n",
    "                                 reverse=True)[:5]\n",
    "                \n",
    "                logger.info(f\"\\n测试数据 - 前5个架构字符串和准确率:\")\n",
    "                for i, (arch_str, arch_info) in enumerate(top_archs):\n",
    "                    logger.info(f\"{i+1}. {arch_str} -> {arch_info['val_acc_200']}\")\n",
    "                \n",
    "                # 将架构字符串转换为配置字典\n",
    "                for arch_str, arch_info in top_archs:\n",
    "                    try:\n",
    "                        config = self._parse_nasbench201_arch(arch_str)\n",
    "                        if config:\n",
    "                            all_archs.append(config)\n",
    "                            all_perfs.append(arch_info['val_acc_200'])\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"解析架构 {arch_str} 失败: {str(e)}\")\n",
    "                        continue\n",
    "                        \n",
    "                logger.info(f\"从 {file_path} 加载了 {len(top_archs)} 个架构\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"加载 {file_path} 失败: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not all_archs:\n",
    "            return [], []\n",
    "        \n",
    "        return all_archs, all_perfs\n",
    "\n",
    "    def _parse_nasbench201_arch(self, arch_str: str) -> Dict:\n",
    "        \"\"\"解析NASBench201的架构字符串为配置字典\"\"\"\n",
    "        # 初始化配置字典\n",
    "        config = {\n",
    "            'stages': {\n",
    "                '0': {'blocks': []},\n",
    "                '1': {'blocks': []},\n",
    "                '2': {'blocks': []}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # 分割字符串获取各阶段信息\n",
    "            parts = arch_str.split('+')\n",
    "            \n",
    "            # 处理每个阶段\n",
    "            for stage_idx, part in enumerate(parts):\n",
    "                # 移除管道符和空白字符\n",
    "                part = part.replace('|', '').strip()\n",
    "                if not part:\n",
    "                    continue\n",
    "                    \n",
    "                # 分割节点\n",
    "                nodes = part.split('~')\n",
    "                for node in nodes:\n",
    "                    if not node:\n",
    "                        continue\n",
    "                        \n",
    "                    # 解析操作和节点索引\n",
    "                    if '~' in node:  # 确保有分隔符\n",
    "                        op, node_idx = node.rsplit('~', 1)\n",
    "                        config['stages'][str(stage_idx)]['blocks'].append({\n",
    "                            'type': op,\n",
    "                            'node_idx': int(node_idx)\n",
    "                        })\n",
    "                    \n",
    "            return config\n",
    "        except Exception as e:\n",
    "            logger.error(f\"解析NASBench201架构 {arch_str} 失败: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# 测试代码\n",
    "def test_nasbench201_loader():\n",
    "    print(\"=\"*50)\n",
    "    print(\"开始测试 NASBench201 加载器\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    loader = NASBench201Loader()\n",
    "    \n",
    "    # 测试单个架构解析\n",
    "    test_arch = \"|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\"\n",
    "    print(f\"\\n测试单个架构解析: {test_arch}\")\n",
    "    parsed = loader._parse_nasbench201_arch(test_arch)\n",
    "    print(\"解析结果:\")\n",
    "    pprint(parsed)\n",
    "    \n",
    "    # 测试加载函数\n",
    "    print(\"\\n测试加载函数...\")\n",
    "    archs, perfs = loader._load_initial_architectures()\n",
    "    \n",
    "    print(\"\\n加载结果概要:\")\n",
    "    print(f\"加载的架构数量: {len(archs)}\")\n",
    "    print(f\"加载的性能指标数量: {len(perfs)}\")\n",
    "    \n",
    "    if archs and perfs:\n",
    "        print(\"\\n第一个架构的详细信息和性能:\")\n",
    "        print(f\"准确率: {perfs[0]}\")\n",
    "        print(\"架构配置:\")\n",
    "        pprint(archs[0])\n",
    "        \n",
    "        print(\"\\n所有架构的性能指标:\")\n",
    "        print(perfs)\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NASBench201Loader:\n",
    "    def _load_initial_architectures(self) -> Tuple[List[Dict], List[float]]:\n",
    "        \"\"\"测试用简化版本，只加载一个文件\"\"\"\n",
    "        dataset_files = [\n",
    "            '/root/tinyml/tnas_background/nasbench201_imagenet.json'  # 只测试一个文件\n",
    "        ]\n",
    "        \n",
    "        all_archs = []\n",
    "        all_perfs = []\n",
    "        \n",
    "        for file_path in dataset_files:\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    arch_data = json.load(f)\n",
    "                \n",
    "                # 只取前5个用于测试\n",
    "                top_archs = sorted(arch_data.items(), \n",
    "                                 key=lambda x: x[1]['val_acc_200'], \n",
    "                                 reverse=True)[:5]\n",
    "                \n",
    "                logger.info(f\"\\n测试数据 - 前5个架构字符串和准确率:\")\n",
    "                for i, (arch_str, arch_info) in enumerate(top_archs):\n",
    "                    logger.info(f\"{i+1}. {arch_str} -> {arch_info['val_acc_200']}\")\n",
    "                \n",
    "                # 将架构字符串转换为配置字典\n",
    "                for arch_str, arch_info in top_archs:\n",
    "                    try:\n",
    "                        config = self._parse_nasbench201_arch(arch_str)\n",
    "                        if config:\n",
    "                            all_archs.append(config)\n",
    "                            all_perfs.append(arch_info['val_acc_200'])\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"解析架构 {arch_str} 失败: {str(e)}\")\n",
    "                        continue\n",
    "                        \n",
    "                logger.info(f\"从 {file_path} 加载了 {len(top_archs)} 个架构\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"加载 {file_path} 失败: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not all_archs:\n",
    "            return [], []\n",
    "        \n",
    "        return all_archs, all_perfs\n",
    "\n",
    "    def _parse_nasbench201_arch(self, arch_str: str) -> Dict:\n",
    "        \"\"\"解析NASBench201的架构字符串为配置字典\"\"\"\n",
    "        # 初始化配置字典\n",
    "        config = {\n",
    "            'stages': {\n",
    "                '0': {'blocks': []},\n",
    "                '1': {'blocks': []},\n",
    "                '2': {'blocks': []}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # 分割字符串获取各阶段信息\n",
    "            parts = [p.strip() for p in arch_str.split('+')]\n",
    "            \n",
    "            # 处理每个阶段\n",
    "            for stage_idx, part in enumerate(parts):\n",
    "                # 移除管道符和空白字符\n",
    "                part = part.replace('|', ' ').strip()\n",
    "                if not part:\n",
    "                    continue\n",
    "                    \n",
    "                # 分割节点 - 现在正确处理形如 \"nor_conv_3x3~0\" 的节点\n",
    "                nodes = [n.strip() for n in part.split() if n.strip()]\n",
    "                for node in nodes:\n",
    "                    if not node or '~' not in node:\n",
    "                        continue\n",
    "                        \n",
    "                    # 解析操作和节点索引\n",
    "                    op, node_idx = node.split('~')\n",
    "                    config['stages'][str(stage_idx)]['blocks'].append({\n",
    "                        'type': op,\n",
    "                        'node_idx': int(node_idx)\n",
    "                    })\n",
    "                    \n",
    "            return config\n",
    "        except Exception as e:\n",
    "            logger.error(f\"解析NASBench201架构 {arch_str} 失败: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# 测试代码\n",
    "def test_nasbench201_loader():\n",
    "    print(\"=\"*50)\n",
    "    print(\"开始测试 NASBench201 加载器\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    loader = NASBench201Loader()\n",
    "    \n",
    "    # 测试单个架构解析\n",
    "    test_arch = \"|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\"\n",
    "    print(f\"\\n测试单个架构解析: {test_arch}\")\n",
    "    parsed = loader._parse_nasbench201_arch(test_arch)\n",
    "    print(\"解析结果:\")\n",
    "    pprint(parsed)\n",
    "    \n",
    "    # 测试加载函数\n",
    "    print(\"\\n测试加载函数...\")\n",
    "    archs, perfs = loader._load_initial_architectures()\n",
    "    \n",
    "    print(\"\\n加载结果概要:\")\n",
    "    print(f\"加载的架构数量: {len(archs)}\")\n",
    "    print(f\"加载的性能指标数量: {len(perfs)}\")\n",
    "    \n",
    "    if archs and perfs:\n",
    "        print(\"\\n第一个架构的详细信息和性能:\")\n",
    "        print(f\"准确率: {perfs[0]}\")\n",
    "        print(\"架构配置:\")\n",
    "        pprint(archs[0])\n",
    "        \n",
    "        print(\"\\n所有架构的性能指标:\")\n",
    "        print(perfs)\n",
    "\n",
    "\n",
    "# 运行测试\n",
    "test_nasbench201_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c7be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 08:36:51,684 - __main__ - INFO - 从 /root/tinyml/tnas_background/nasbench201_cifar10.json 加载了 25 个架构\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 08:36:51,734 - __main__ - INFO - 从 /root/tinyml/tnas_background/nasbench201_cifar100.json 加载了 25 个架构\n",
      "2025-07-20 08:36:51,777 - __main__ - INFO - 从 /root/tinyml/tnas_background/nasbench201_imagenet.json 加载了 25 个架构\n",
      "2025-07-20 08:36:51,778 - __main__ - INFO - 加载的架构来源统计: {'cifar10': 25, 'cifar100': 25, 'imagenet': 25}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "开始测试 NASBench201 加载器\n",
      "==================================================\n",
      "\n",
      "测试单个架构解析: |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "解析结果:\n",
      "{'stages': {'0': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_3x3'}]},\n",
      "            '1': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_1x1'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_1x1'}]},\n",
      "            '2': {'blocks': [{'node_idx': 0, 'type': 'skip_connect'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_3x3'},\n",
      "                             {'node_idx': 2, 'type': 'nor_conv_3x3'}]}}}\n",
      "\n",
      "测试加载函数...\n",
      "\n",
      "加载结果概要:\n",
      "加载的架构数量: 50\n",
      "加载的性能指标数量: 50\n",
      "加载的架构来源数量: 50\n",
      "\n",
      "第一个架构的详细信息和性能:\n",
      "准确率: 91.60666665039064\n",
      "架构配置:\n",
      "{'stages': {'0': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_3x3'}]},\n",
      "            '1': {'blocks': [{'node_idx': 0, 'type': 'nor_conv_3x3'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_3x3'}]},\n",
      "            '2': {'blocks': [{'node_idx': 0, 'type': 'skip_connect'},\n",
      "                             {'node_idx': 1, 'type': 'nor_conv_3x3'},\n",
      "                             {'node_idx': 2, 'type': 'nor_conv_1x1'}]}}}\n",
      "\n",
      "所有架构的性能指标:\n",
      "[91.60666665039064, 91.56800001220704, 91.5533333235677, 91.55199997558594, 91.54399997314454, 91.53333331461589, 91.51599999023438, 91.50533331298827, 91.49599997884116, 91.44799998860678, 91.43999998453775, 91.42399998779297, 91.42266665120444, 91.41999999023437, 91.41999998535157, 91.41800000122069, 91.38999999023437, 91.37799998168944, 91.36533333251953, 91.35999999267578, 91.35999997802735, 91.356, 91.35066664876302, 91.34799999755859, 91.34399999267578, 73.01999998779297, 72.98000002441407, 72.9599999206543, 72.71999991455078, 72.59333336181642, 72.52999996337891, 72.51999997558593, 72.51333330078126, 72.43333326416017, 72.41999991455077, 46.5166666615804, 46.49999995422363, 46.48888883463542, 46.46666666666667, 46.44999995930989, 46.39999984741211, 46.36666665649414, 46.34999992370605, 46.31666653442383, 46.23333331298828, 46.21666658528646, 46.183333302815754, 46.183333206176755, 46.08888888549805, 46.0666665242513]\n",
      "\n",
      "所有架构的来源:\n",
      "['cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar10', 'cifar100', 'cifar100', 'cifar100', 'cifar100', 'cifar100', 'cifar100', 'cifar100', 'cifar100', 'cifar100', 'cifar100', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet', 'imagenet']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NASBench201Loader:\n",
    "    def _load_initial_architectures(self) -> Tuple[List[Dict], List[float]]:\n",
    "        \"\"\"测试用简化版本，只加载一个文件\"\"\"\n",
    "        dataset_files = [\n",
    "            '/root/tinyml/tnas_background/nasbench201_cifar10.json',\n",
    "            '/root/tinyml/tnas_background/nasbench201_cifar100.json',\n",
    "            '/root/tinyml/tnas_background/nasbench201_imagenet.json'\n",
    "        ]\n",
    "        \n",
    "        all_archs = []\n",
    "        all_perfs = []\n",
    "        all_sources = []  # 记录每个架构来自哪个数据集\n",
    "        \n",
    "        for file_path in dataset_files:\n",
    "            try:\n",
    "                # 从文件路径提取数据集名称\n",
    "                dataset_name = file_path.split('/')[-1].replace('nasbench201_', '').replace('.json', '')\n",
    "                with open(file_path, 'r') as f:\n",
    "                    arch_data = json.load(f)\n",
    "                \n",
    "                # 只取前5个用于测试\n",
    "                top_archs = sorted(arch_data.items(), \n",
    "                                 key=lambda x: x[1]['val_acc_200'], \n",
    "                                 reverse=True)[:25]\n",
    "                \n",
    "                # 将架构字符串转换为配置字典\n",
    "                for arch_str, arch_info in top_archs:\n",
    "                    try:\n",
    "                        config = self._parse_nasbench201_arch(arch_str)\n",
    "                        if config:\n",
    "                            all_archs.append(config)\n",
    "                            all_perfs.append(arch_info['val_acc_200'])\n",
    "                            all_sources.append(dataset_name)\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"解析架构 {arch_str} 失败: {str(e)}\")\n",
    "                        continue\n",
    "                        \n",
    "                logger.info(f\"从 {file_path} 加载了 {len(top_archs)} 个架构\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"加载 {file_path} 失败: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not all_archs:\n",
    "            return [], []\n",
    "\n",
    "        # 统计各数据集的架构数量\n",
    "        source_stats = {name: all_sources.count(name) for name in ['cifar10', 'cifar100', 'imagenet']}\n",
    "        logger.info(f\"加载的架构来源统计: {source_stats}\")\n",
    "        \n",
    "        # 返回去重后的架构(保留75个，每个数据集25个)\n",
    "        unique_archs = []\n",
    "        unique_perfs = []\n",
    "        unique_sources = []\n",
    "        seen_archs = set()\n",
    "        \n",
    "        for arch, perf, source in zip(all_archs, all_perfs, all_sources):\n",
    "            arch_str = json.dumps(arch, sort_keys=True)\n",
    "            if arch_str not in seen_archs:\n",
    "                seen_archs.add(arch_str)\n",
    "                unique_archs.append(arch)\n",
    "                unique_perfs.append(perf)\n",
    "                unique_sources.append(source)\n",
    "        \n",
    "        return unique_archs, unique_perfs, unique_sources\n",
    "\n",
    "    def _parse_nasbench201_arch(self, arch_str: str) -> Dict:\n",
    "        \"\"\"解析NASBench201的架构字符串为配置字典\"\"\"\n",
    "        # 初始化配置字典\n",
    "        config = {\n",
    "            'stages': {\n",
    "                '0': {'blocks': []},\n",
    "                '1': {'blocks': []},\n",
    "                '2': {'blocks': []}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # 分割字符串获取各阶段信息\n",
    "            parts = [p.strip() for p in arch_str.split('+')]\n",
    "            \n",
    "            # 处理每个阶段\n",
    "            for stage_idx, part in enumerate(parts):\n",
    "                # 移除管道符和空白字符\n",
    "                part = part.replace('|', ' ').strip()\n",
    "                if not part:\n",
    "                    continue\n",
    "                    \n",
    "                # 分割节点 - 现在正确处理形如 \"nor_conv_3x3~0\" 的节点\n",
    "                nodes = [n.strip() for n in part.split() if n.strip()]\n",
    "                for node in nodes:\n",
    "                    if not node or '~' not in node:\n",
    "                        continue\n",
    "                        \n",
    "                    # 解析操作和节点索引\n",
    "                    op, node_idx = node.split('~')\n",
    "                    config['stages'][str(stage_idx)]['blocks'].append({\n",
    "                        'type': op,\n",
    "                        'node_idx': int(node_idx)\n",
    "                    })\n",
    "                    \n",
    "            return config\n",
    "        except Exception as e:\n",
    "            logger.error(f\"解析NASBench201架构 {arch_str} 失败: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# 测试代码\n",
    "def test_nasbench201_loader():\n",
    "    print(\"=\"*50)\n",
    "    print(\"开始测试 NASBench201 加载器\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    loader = NASBench201Loader()\n",
    "    \n",
    "    # 测试单个架构解析\n",
    "    test_arch = \"|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\"\n",
    "    print(f\"\\n测试单个架构解析: {test_arch}\")\n",
    "    parsed = loader._parse_nasbench201_arch(test_arch)\n",
    "    print(\"解析结果:\")\n",
    "    pprint(parsed)\n",
    "    \n",
    "    # 测试加载函数\n",
    "    print(\"\\n测试加载函数...\")\n",
    "    archs, perfs, sources = loader._load_initial_architectures()\n",
    "    \n",
    "    print(\"\\n加载结果概要:\")\n",
    "    print(f\"加载的架构数量: {len(archs)}\")\n",
    "    print(f\"加载的性能指标数量: {len(perfs)}\")\n",
    "    print(f\"加载的架构来源数量: {len(sources)}\")\n",
    "    \n",
    "    if archs and perfs and sources:\n",
    "        print(\"\\n第一个架构的详细信息和性能:\")\n",
    "        print(f\"准确率: {perfs[0]}\")\n",
    "        print(\"架构配置:\")\n",
    "        pprint(archs[0])\n",
    "        \n",
    "        print(\"\\n所有架构的性能指标:\")\n",
    "        print(perfs)\n",
    "\n",
    "        print(\"\\n所有架构的来源:\")\n",
    "        print(sources)\n",
    "\n",
    "# 运行测试\n",
    "test_nasbench201_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419d6443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ModelGPT/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 是否可用: True\n",
      "可用 GPU 数量: 4\n",
      "当前 GPU 名称: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否支持 CUDA\n",
    "print(\"CUDA 是否可用:\", torch.cuda.is_available())\n",
    "\n",
    "# 检查可用的 GPU 数量\n",
    "print(\"可用 GPU 数量:\", torch.cuda.device_count())\n",
    "\n",
    "# 如果有可用 GPU，打印 GPU 的名称\n",
    "if torch.cuda.is_available():\n",
    "    print(\"当前 GPU 名称:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"没有可用的 CUDA GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89468f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 X_train 形状: (6840, 125, 45)\n",
      "原始 X_test 形状: (2280, 125, 45)\n",
      "填充后 X_train 形状: (6840, 2500, 45)\n",
      "填充后 X_test 形状: (2280, 2500, 45)\n",
      "数据预处理完成，填充后的数据已保存。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 数据集路径\n",
    "data_path = \"/root/tinyml/data/DSADS\"\n",
    "\n",
    "# 时间步扩充目标\n",
    "target_time_steps = 2500\n",
    "\n",
    "# 加载数据\n",
    "X_train = np.load(os.path.join(data_path, \"X_train.npy\"))\n",
    "X_test = np.load(os.path.join(data_path, \"X_test.npy\"))\n",
    "y_train = np.load(os.path.join(data_path, \"y_train.npy\"))\n",
    "y_test = np.load(os.path.join(data_path, \"y_test.npy\"))\n",
    "\n",
    "# 打印原始数据形状\n",
    "print(\"原始 X_train 形状:\", X_train.shape)  # (9120, 125, 45)\n",
    "print(\"原始 X_test 形状:\", X_test.shape)    # (样本数量, 125, 45)\n",
    "\n",
    "# 检查时间步是否需要扩充\n",
    "original_time_steps = X_train.shape[1]\n",
    "if original_time_steps >= target_time_steps:\n",
    "    raise ValueError(f\"目标时间步 {target_time_steps} 小于或等于原始时间步 {original_time_steps}，无需扩充。\")\n",
    "\n",
    "# 定义零填充函数\n",
    "def pad_time_steps(data, target_time_steps):\n",
    "    \"\"\"\n",
    "    对输入数据在时间步维度上进行零填充。\n",
    "    \n",
    "    参数:\n",
    "        data: numpy 数组，形状为 (样本数量, 时间步, 通道数量)\n",
    "        target_time_steps: int，目标时间步数量\n",
    "    \n",
    "    返回:\n",
    "        填充后的数据，形状为 (样本数量, target_time_steps, 通道数量)\n",
    "    \"\"\"\n",
    "    num_samples, original_time_steps, num_channels = data.shape\n",
    "    # 创建一个全零数组，形状为 (样本数量, target_time_steps, 通道数量)\n",
    "    padded_data = np.zeros((num_samples, target_time_steps, num_channels))\n",
    "    # 将原始数据复制到新数组中\n",
    "    padded_data[:, :original_time_steps, :] = data\n",
    "    return padded_data\n",
    "\n",
    "# 对训练集和测试集进行填充\n",
    "X_train_padded = pad_time_steps(X_train, target_time_steps)\n",
    "X_test_padded = pad_time_steps(X_test, target_time_steps)\n",
    "\n",
    "# 打印填充后的数据形状\n",
    "print(\"填充后 X_train 形状:\", X_train_padded.shape)  # (9120, 2500, 45)\n",
    "print(\"填充后 X_test 形状:\", X_test_padded.shape)    # (样本数量, 2500, 45)\n",
    "\n",
    "save_path = \"/root/tinyml/data/DSADS1\"\n",
    "# 保存填充后的数据\n",
    "np.save(os.path.join(save_path, \"X_train.npy\"), X_train_padded)\n",
    "np.save(os.path.join(save_path, \"X_test.npy\"), X_test_padded)\n",
    "\n",
    "# 标签无需填充，直接保存\n",
    "np.save(os.path.join(save_path, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(save_path, \"y_test.npy\"), y_test)\n",
    "\n",
    "print(\"数据预处理完成，填充后的数据已保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de4fb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 X_train 形状: (12406, 200, 6)\n",
      "原始 X_test 形状: (3045, 200, 6)\n",
      "填充后 X_train 形状: (12406, 2500, 45)\n",
      "填充后 X_test 形状: (3045, 2500, 45)\n",
      "数据预处理完成，填充后的数据已保存。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 数据集路径\n",
    "data_path = \"/root/tinyml/data/WISDM\"\n",
    "\n",
    "# 时间步扩充目标\n",
    "target_time_steps = 2500\n",
    "target_channels = 45  # 假设通道数为45\n",
    "\n",
    "# 加载数据\n",
    "X_train = np.load(os.path.join(data_path, \"X_train.npy\"))\n",
    "X_test = np.load(os.path.join(data_path, \"X_test.npy\"))\n",
    "y_train = np.load(os.path.join(data_path, \"y_train.npy\"))\n",
    "y_test = np.load(os.path.join(data_path, \"y_test.npy\"))\n",
    "\n",
    "# 打印原始数据形状\n",
    "print(\"原始 X_train 形状:\", X_train.shape)  # (9120, 125, 45)\n",
    "print(\"原始 X_test 形状:\", X_test.shape)    # (样本数量, 125, 45)\n",
    "\n",
    "# 检查时间步是否需要扩充\n",
    "original_time_steps = X_train.shape[1]\n",
    "if original_time_steps > target_time_steps:\n",
    "    raise ValueError(f\"目标时间步 {target_time_steps} 小于或等于原始时间步 {original_time_steps}，无需扩充。\")\n",
    "\n",
    "# 定义零填充函数\n",
    "def pad_time_steps(data, target_time_steps):\n",
    "    \"\"\"\n",
    "    对输入数据在时间步维度上进行零填充。\n",
    "    \n",
    "    参数:\n",
    "        data: numpy 数组，形状为 (样本数量, 时间步, 通道数量)\n",
    "        target_time_steps: int，目标时间步数量\n",
    "    \n",
    "    返回:\n",
    "        填充后的数据，形状为 (样本数量, target_time_steps, 通道数量)\n",
    "    \"\"\"\n",
    "    num_samples, original_time_steps, num_channels = data.shape\n",
    "    # 创建一个全零数组，形状为 (样本数量, target_time_steps, 通道数量)\n",
    "    padded_data = np.zeros((num_samples, target_time_steps, target_channels))\n",
    "    # 将原始数据复制到新数组中\n",
    "    padded_data[:, :original_time_steps, :num_channels] = data\n",
    "    return padded_data\n",
    "\n",
    "# 对训练集和测试集进行填充\n",
    "X_train_padded = pad_time_steps(X_train, target_time_steps)\n",
    "X_test_padded = pad_time_steps(X_test, target_time_steps)\n",
    "\n",
    "# 打印填充后的数据形状\n",
    "print(\"填充后 X_train 形状:\", X_train_padded.shape)  # (9120, 2500, 45)\n",
    "print(\"填充后 X_test 形状:\", X_test_padded.shape)    # (样本数量, 2500, 45)\n",
    "\n",
    "save_path = \"/root/tinyml/data/WISDM1\"\n",
    "# 保存填充后的数据\n",
    "np.save(os.path.join(save_path, \"X_train.npy\"), X_train_padded)\n",
    "np.save(os.path.join(save_path, \"X_test.npy\"), X_test_padded)\n",
    "\n",
    "# 标签无需填充，直接保存\n",
    "np.save(os.path.join(save_path, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(save_path, \"y_test.npy\"), y_test)\n",
    "\n",
    "print(\"数据预处理完成，填充后的数据已保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "812f7a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 X_train 形状: (1102, 320, 3)\n",
      "原始 X_test 形状: (220, 320, 3)\n",
      "填充后 X_train 形状: (1102, 2500, 45)\n",
      "填充后 X_test 形状: (220, 2500, 45)\n",
      "数据预处理完成，填充后的数据已保存。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 数据集路径\n",
    "data_path = \"/root/tinyml/data/Wharf\"\n",
    "\n",
    "# 时间步扩充目标\n",
    "target_time_steps = 2500\n",
    "target_channels = 45  # 假设通道数为45\n",
    "\n",
    "# 加载数据\n",
    "X_train = np.load(os.path.join(data_path, \"X_train.npy\"))\n",
    "X_test = np.load(os.path.join(data_path, \"X_test.npy\"))\n",
    "y_train = np.load(os.path.join(data_path, \"y_train.npy\"))\n",
    "y_test = np.load(os.path.join(data_path, \"y_test.npy\"))\n",
    "\n",
    "# 打印原始数据形状\n",
    "print(\"原始 X_train 形状:\", X_train.shape)  # (9120, 125, 45)\n",
    "print(\"原始 X_test 形状:\", X_test.shape)    # (样本数量, 125, 45)\n",
    "\n",
    "# 检查时间步是否需要扩充\n",
    "original_time_steps = X_train.shape[1]\n",
    "if original_time_steps > target_time_steps:\n",
    "    raise ValueError(f\"目标时间步 {target_time_steps} 小于或等于原始时间步 {original_time_steps}，无需扩充。\")\n",
    "\n",
    "# 定义零填充函数\n",
    "def pad_time_steps(data, target_time_steps):\n",
    "    \"\"\"\n",
    "    对输入数据在时间步维度上进行零填充。\n",
    "    \n",
    "    参数:\n",
    "        data: numpy 数组，形状为 (样本数量, 时间步, 通道数量)\n",
    "        target_time_steps: int，目标时间步数量\n",
    "    \n",
    "    返回:\n",
    "        填充后的数据，形状为 (样本数量, target_time_steps, 通道数量)\n",
    "    \"\"\"\n",
    "    num_samples, original_time_steps, num_channels = data.shape\n",
    "    # 创建一个全零数组，形状为 (样本数量, target_time_steps, 通道数量)\n",
    "    padded_data = np.zeros((num_samples, target_time_steps, target_channels))\n",
    "    # 将原始数据复制到新数组中\n",
    "    padded_data[:, :original_time_steps, :num_channels] = data\n",
    "    return padded_data\n",
    "\n",
    "# 对训练集和测试集进行填充\n",
    "X_train_padded = pad_time_steps(X_train, target_time_steps)\n",
    "X_test_padded = pad_time_steps(X_test, target_time_steps)\n",
    "\n",
    "# 打印填充后的数据形状\n",
    "print(\"填充后 X_train 形状:\", X_train_padded.shape)  # (9120, 2500, 45)\n",
    "print(\"填充后 X_test 形状:\", X_test_padded.shape)    # (样本数量, 2500, 45)\n",
    "\n",
    "save_path = \"/root/tinyml/data/Wharf1\"\n",
    "# 保存填充后的数据\n",
    "np.save(os.path.join(save_path, \"X_train.npy\"), X_train_padded)\n",
    "np.save(os.path.join(save_path, \"X_test.npy\"), X_test_padded)\n",
    "\n",
    "# 标签无需填充，直接保存\n",
    "np.save(os.path.join(save_path, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(save_path, \"y_test.npy\"), y_test)\n",
    "\n",
    "print(\"数据预处理完成，填充后的数据已保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315a2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 121 个动作标签。\n"
     ]
    }
   ],
   "source": [
    "global_label = [\n",
    "    \"arm curl (two arms)\",\n",
    "    \"ascending stairs\",\n",
    "    \"basketball shoot\",\n",
    "    \"baseball swing from right\",\n",
    "    \"brushing teeth\",\n",
    "    \"carrying\",\n",
    "    \"carrying heavy\",\n",
    "    \"carrying light\",\n",
    "    \"checking time\",\n",
    "    \"clapping\",\n",
    "    \"climbing down\",\n",
    "    \"climbing stairs\",\n",
    "    \"climbing up\",\n",
    "    \"closing\",\n",
    "    \"comb hair\",\n",
    "    \"crouching\",\n",
    "    \"cycling\",\n",
    "    \"cycling on an exercise bike in horizontal positions\",\n",
    "    \"cycling on an exercise bike in vertical positions\",\n",
    "    \"cycling sitting\",\n",
    "    \"cycling sitting inactive\",\n",
    "    \"cycling standing\",\n",
    "    \"cycling standing inactive\",\n",
    "    \"descending stairs\",\n",
    "    \"drink glass\",\n",
    "    \"drinking\",\n",
    "    \"drinking coffee\",\n",
    "    \"drinking cup\",\n",
    "    \"draw triangle\",\n",
    "    \"eating\",\n",
    "    \"eating chips\",\n",
    "    \"eating meat\",\n",
    "    \"eating pasta\",\n",
    "    \"eating sandwich\",\n",
    "    \"eating soup\",\n",
    "    \"elevator down\",\n",
    "    \"elevator up\",\n",
    "    \"exercising on a cross trainer\",\n",
    "    \"exercising on a stepper\",\n",
    "    \"exiting\",\n",
    "    \"fall\",\n",
    "    \"folding clothes\",\n",
    "    \"forward lunge (left foot forward)\",\n",
    "    \"frontal elevation of arms\",\n",
    "    \"get up bed\",\n",
    "    \"giving a talk\",\n",
    "    \"iron\",\n",
    "    \"jogging\",\n",
    "    \"jogging in place\",\n",
    "    \"jump front and back\",\n",
    "    \"jump up\",\n",
    "    \"jumping\",\n",
    "    \"kicking\",\n",
    "    \"knees bending crouching\",\n",
    "    \"lie\",\n",
    "    # \"lie down\",\n",
    "    # \"lie down bed\",\n",
    "    \"loitering\",\n",
    "    \"looking around\",\n",
    "    # \"lying\",\n",
    "    # \"lying down\",\n",
    "    \"lying on back\",\n",
    "    \"lying on right side\",\n",
    "    \"moving around in an elevator\",\n",
    "    \"nordic walking\",\n",
    "    \"opening\",\n",
    "    \"picking up\",\n",
    "    \"playing ball\",\n",
    "    \"playing basketball\",\n",
    "    \"pointing\",\n",
    "    \"pour water\",\n",
    "    \"pulling\",\n",
    "    \"pushing\",\n",
    "    \"pocket in\",\n",
    "    \"pocket out\",\n",
    "    \"right arm swipe to the left\",\n",
    "    \"right arm swipe to the right\",\n",
    "    \"right arm throw\",\n",
    "    \"right hand catch an object\",\n",
    "    \"right hand draw circle (clockwise)\",\n",
    "    \"right hand draw circle (counter clockwise)\",\n",
    "    \"right hand draw x\",\n",
    "    \"right hand knock on door\",\n",
    "    \"right hand pick up and throw\",\n",
    "    \"right hand wave\",\n",
    "    \"rope jumping\",\n",
    "    \"rowing\",\n",
    "    \"running\",\n",
    "    \"running on a treadmill fast\",\n",
    "    \"setting down\",\n",
    "    \"shuffling\",\n",
    "    \"sit\",\n",
    "    \"sit down chair\",\n",
    "    \"sit up chair\"\n",
    "    \"sit to stand\",\n",
    "    # \"sitting\",\n",
    "    \"sitting down\",\n",
    "    \"sitting relaxing\",\n",
    "    \"sleep\",\n",
    "    \"smoking\",\n",
    "    \"squat (two arms stretch out)\",\n",
    "    \"stand\",\n",
    "    \"stand to sit\",\n",
    "    \"stand up chair\",\n",
    "    # \"standing\",\n",
    "    \"standing in an elevator still\",\n",
    "    \"standing still\",\n",
    "    \"standing up\",\n",
    "    \"stairs\",\n",
    "    # \"stairs ascending\",\n",
    "    # \"stairs descending\",\n",
    "    # \"stairs down\",\n",
    "    # \"stairs up\",\n",
    "    \"talking\",\n",
    "    \"talking on phone\",\n",
    "    \"tennis right hand forehand swing\",\n",
    "    \"tennis serve\",\n",
    "    \"throwing\",\n",
    "    \"transferring object\",\n",
    "    \"two hand front clap\",\n",
    "    \"two hand push\",\n",
    "    \"typing\",\n",
    "    \"using pc\",\n",
    "    \"using phone\",\n",
    "    \"use telephone\",\n",
    "    \"vacuum cleaning\",\n",
    "    \"walking\",\n",
    "    \"walking in place\",\n",
    "    \"walking on a treadmill in flat positions\",\n",
    "    \"walking on a treadmill in inclined positions\",\n",
    "    \"waving hand\",\n",
    "    \"writing\"\n",
    "]\n",
    "\n",
    "label_length = len(global_label)\n",
    "print(f\"共有 {label_length} 个动作标签。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModelGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
