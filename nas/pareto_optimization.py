from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from models.candidate_models import CandidateModel
import json
import json5

# MACsï¼ˆMultiply-Accumulate Operationsï¼Œä¹˜ç§¯ç´¯åŠ è¿ç®—ï¼‰
class ParetoFront:
    """ç®¡ç†Paretoå‰æ²¿å¹¶è¿›è¡Œå¤šç›®æ ‡ä¼˜åŒ–"""
    
    def __init__(self, top_k: int = 3, constraints: Optional[Dict[str, float]] = None):
        self.front: List[CandidateModel] = []  # Paretoå‰æ²¿è§£é›†
        self.best_accuracy_model: Optional[CandidateModel] = None  # æœ€ä½³å‡†ç¡®ç‡æ¨¡å‹
        self.best_accuracy: float = -1  # æœ€ä½³å‡†ç¡®ç‡å€¼
        self.history: List[Dict] = []  # æœç´¢å†å²è®°å½•
        self.top_k = top_k  # ç”¨äºåé¦ˆçš„å‰Kä¸ªæ¶æ„
        # self.metrics

        self.constraints = constraints or {
            'max_sram': 2000 * 1024,  # é»˜è®¤å€¼ 128KB
            'min_macs': 2 * 1e6,    # é»˜è®¤å€¼ 10M MACs
            'max_macs': 200 * 1e6,    # é»˜è®¤å€¼ 100M MACs
            'max_params': 5 * 1e6  # é»˜è®¤å€¼ 10M å‚æ•°é‡
        }
              
    def update(self, candidate: CandidateModel, metrics: Dict[str, float]) -> bool:
        """
            æ›´æ–° Pareto å‰æ²¿ï¼Œæ·»åŠ æ–°çš„å€™é€‰æ¨¡å‹

            å‚æ•°:
                candidate: å€™é€‰æ¨¡å‹å®ä¾‹
                metrics: è¯„ä¼°æŒ‡æ ‡å­—å…¸ {'accuracy', 'macs', 'params', 'sram', 'latency', 'peak_memory'}

            è¿”å›:
                bool: æ˜¯å¦æˆåŠŸåŠ å…¥ Pareto å‰æ²¿
        """
        
        # è®°å½•å†å²æ•°æ®
        self.history.append({
            'iteration': len(self.history) + 1,
            'accuracy': metrics['accuracy'],
            'val_accuracy': metrics['val_accuracy'],
            'macs': metrics['macs'],
            'params': metrics['params'],
            'sram': metrics['sram'],
            'latency': metrics.get('latency', 0),  # æ–°å¢latencyè®°å½•
            'peak_memory': metrics.get('peak_memory', 0),
            'config': candidate.config,
            'best_model_path': candidate.metadata.get('best_model_path')  # ä¿å­˜æœ€ä½³æƒé‡è·¯å¾„
        })
        print(f"ğŸ” æ›´æ–°å€™é€‰æ¨¡å‹ macs: {metrics['macs']} params: {metrics['params']} sram:{float(metrics['sram']) / 1024} latency: {metrics.get('latency', 0):.2f}ms peak_memory: {float(metrics['peak_memory'])}MB")
        # æ›´æ–°æœ€ä½³å‡†ç¡®ç‡æ¨¡å‹
        if metrics['accuracy'] > self.best_accuracy:
            self.best_accuracy = metrics['accuracy']
            self.best_accuracy_model = candidate
            print(f"ğŸ¯ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {self.best_accuracy:.2f}%")

        # æ£€æŸ¥æ˜¯å¦è¢«å‰æ²¿ä¸­çš„ä»»ä½•è§£æ”¯é…
        is_dominated = any(self._dominates(existing.metrics, metrics) 
                      for existing in self.front)

        
        # å¦‚æœæœªè¢«æ”¯é…ï¼Œåˆ™åŠ å…¥å‰æ²¿å¹¶ç§»é™¤è¢«å®ƒæ”¯é…çš„è§£
        if not is_dominated:
            # candidate.metrics = metrics
            candidate.accuracy = metrics['accuracy']
            candidate.macs = metrics['macs']
            candidate.params = metrics['params']
            candidate.sram = metrics['sram']
            
            candidate.latency = metrics.get('latency', 0)
            candidate.peak_memory = metrics.get('peak_memory', 0)
            candidate.val_accuracy = metrics['val_accuracy']
            candidate.metadata['best_model_path'] = candidate.metadata.get('best_model_path')  # ä¿å­˜è·¯å¾„

            # ç§»é™¤è¢«æ–°è§£æ”¯é…çš„ç°æœ‰è§£
            self.front = [sol for sol in self.front 
                         if not self._dominates(metrics, sol.metrics)]
            # æ·»åŠ æ–°è§£
            self.front.append(candidate)
            
            print(f"ğŸ“ˆ Pareto å‰æ²¿æ›´æ–°: å½“å‰å¤§å°={len(self.front)}")
            return True
        
        print("â– å€™é€‰è¢«æ”¯é…ï¼ŒæœªåŠ å…¥Paretoå‰æ²¿")
        return False

    def _dominates(self, a: Dict[str, float], b: Dict[str, float]) -> bool:
        """
        åˆ¤æ–­è§£aæ˜¯å¦æ”¯é…è§£b (Paretoæ”¯é…å…³ç³»)
        
        å‚æ•°:
            a: ç¬¬ä¸€ä¸ªè§£çš„æŒ‡æ ‡
            b: ç¬¬äºŒä¸ªè§£çš„æŒ‡æ ‡
            
        è¿”å›:
            bool: aæ˜¯å¦æ”¯é…b
        """
        # åœ¨TinyMLåœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›:
        # - å‡†ç¡®ç‡(accuracy)è¶Šé«˜è¶Šå¥½
        # - MACså’Œå‚æ•°é‡(params)è¶Šä½è¶Šå¥½
        
        # # aè‡³å°‘åœ¨ä¸€ä¸ªæŒ‡æ ‡ä¸Šä¸¥æ ¼ä¼˜äºb
        better_in_any = (a['accuracy'] > b['accuracy'] or 
                        a['macs'] < b['macs'] or 
                        a['params'] < b['params'] or
                        a['sram'] < b['sram'] or
                        a.get('latency', 0) < b.get('latency', 0)) or \
                        a.get('peak_memory', 0) < b.get('peak_memory', 0)  
        
        # aåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šä¸å·®äºb
        no_worse_in_all = (a['accuracy'] >= b['accuracy'] and 
                          a['macs'] <= b['macs'] and 
                          a['params'] <= b['params'] and
                          a['sram'] <= b['sram'] and
                          a.get('latency', 0) <= b.get('latency', 0)) and \
                          a.get('peak_memory', 0) <= b.get('peak_memory', 0)

        
        return better_in_any and no_worse_in_all

    def get_feedback(self) -> str:
        """
        ç”Ÿæˆç”¨äºæŒ‡å¯¼LLMæœç´¢çš„åé¦ˆä¿¡æ¯
        
        è¿”å›:
            str: ç»“æ„åŒ–åé¦ˆæ–‡æœ¬
        """
        if not self.front:
            return ("Currently, the Pareto front is empty. Suggestion:\n"
                    "- First, generate an architecture that meets the basic constraints.\n")
        
        # æŒ‰å‡†ç¡®ç‡é™åºæ’åº
        sorted_front = sorted(self.front, 
                            key=lambda x: (-x.accuracy, 
                                            x.macs))


        # --- ç¬¬ä¸€éƒ¨åˆ†ï¼šå‰æ²¿ç»Ÿè®¡ ---

        accuracies = [m.accuracy for m in self.front]
        macs_list = [m.macs for m in self.front]
        params_list = [m.params for m in self.front]
        sram_list = [m.sram for m in self.front]

        latency_list = [m.latency for m in self.front if hasattr(m, 'latency')]

        peak_memory_list = [m.peak_memory for m in self.front if hasattr(m, 'peak_memory')]
        
        avg_acc = np.mean(accuracies)
        avg_macs = np.mean(macs_list)
        avg_params = np.mean(params_list)
        avg_sram = np.mean(sram_list)
        avg_latency = np.mean(latency_list) if latency_list else 0
        avg_peak_memory = np.mean(peak_memory_list) if peak_memory_list else 0
        
        best_acc = max(accuracies)
        min_macs = min(macs_list)
        min_params = min(params_list)
        min_sram = min(sram_list)
        min_latency = min(latency_list) if latency_list else 0
        min_peak_memory = min(peak_memory_list) if peak_memory_list else 0

        feedback = (
            "=== Pareto frontier statistics ===\n"
            f"Front size: {len(self.front)} architecture(s)\n"
            f"Accuracy range: {min(accuracies):.2f}%~{max(accuracies):.2f}%\n"
            # /1e6  /1e6
            f"MACs range: {min(macs_list):.2f}M~{max(macs_list):.2f}M\n"
            # /1e6  /1e6
            f"SRAM range: {min(sram_list)/1024:.2f}KB~{max(sram_list)/1024:.2f}KB\n"
            f"Parameter quantity range: {min(params_list):.2f}M~{max(params_list):.2f}M\n\n"
            f"Front size: {len(self.front)} architecture(s)\n"
            f"Average Accuracy: {avg_acc:.2f}% | Best: {best_acc:.2f}%\n"
            # /1e6 /1e6
            f"Average computation amount: {avg_macs:.2f}M MACs | Minimum: {min_macs:.2f}M\n"
            f"Average SRAM: {avg_sram/1024:.2f}KB | Minimum: {min_sram/1024:.2f}KB\n"
            # /1e6 /1e6
            f"Average parameter amount: {avg_params:.2f}M | Minimum: {min_params:.2f}M\n\n"
            f"Average latency: {avg_latency:.2f} ms | Minimum: {min_latency:.2f} ms\n"
            f"Average peak memory: {avg_peak_memory:.2f} MB | Minimum: {min_peak_memory:.2f} MB\n"
        )

        # --- ç¬¬äºŒéƒ¨åˆ†ï¼šå‰æ²¿æ¶æ„ç¤ºä¾‹ ---
        actual_top_k = min(self.top_k, len(sorted_front))
        feedback += f"=== Reference architecture (Top-{actual_top_k}) ===\n"
        feedback += f"=== Reference architecture (Top-{min(actual_top_k, len(sorted_front))}) ===\n"

        for i, candidate in enumerate(sorted_front[:actual_top_k], 1):
            feedback += (
                f"\nArchitecture #{i}:\n"
                f"- Paramer Path: {candidate.metadata.get('best_model_path', 'N/A')}\n"
                f"- Accuracy: {candidate.accuracy:.2f}%\n"
                # /1e6
                f"- MACs: {candidate.macs:.2f}M\n"
                # /1e6
                f"- Parameters: {candidate.params:.2f}M\n"
                f"- SRAM: {candidate.sram/1e3:.2f}KB\n"
                f"- Latency: {candidate.latency:.2f} ms\n"
                f"- Peak Memory: {candidate.peak_memory:.2f} MB\n"
                # f"- Validation Accuracy by Task: {json.dumps(candidate.val_accuracy, indent=2)}\n"  # è¾“å‡ºå„ä»»åŠ¡çš„éªŒè¯å‡†ç¡®ç‡
                f"- Validation Accuracy: {candidate.val_accuracy:.2%}\n"
                f"- Configuration overview:\n"
                f"  - Number of stages: {len(candidate.config['stages'])}\n"
                f"  - Total blocks: {sum(len(stage['blocks']) for stage in candidate.config['stages'])}\n"
                f"- Full Configuration:\n"
                f"{json.dumps(candidate.config, indent=2)}\n"
            )


        
        # --- ç¬¬ä¸‰éƒ¨åˆ†ï¼šåŠ¨æ€å»ºè®® ---
        
        # æ ¹æ®å‰æ²¿çŠ¶æ€ç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®
        if avg_acc < 65:
            feedback += ("ğŸ”´ Priority: Improve accuracy:\n"
                       "- Increase network depth or width\n"
                       "- Try larger kernels (5x5,7x7)\n"
                       "- Add more SE modules appropriately\n")
        elif avg_macs > float(self.constraints['max_macs'])/1e6:
            feedback += ("ğŸŸ¡ Need to reduce computation:\n"
                       "- Reduce expansion ratio in MBConv\n"
                       "- Use more stride=2 downsampling\n"
                       "- Reduce channels, especially in early layers\n"
                       "- Reduce model size by removing redundant blocks\n")
        elif avg_peak_memory > float(self.constraints['max_peak_memory'])/1e6:
            feedback += ("ğŸŸ  Need to reduce peak memory:\n"
                       "- Ruduce model size by removing redundant blocks (this is the important!!!)\n"
                       "- Reduce channel distribution in later stages\n"
                       "- Use more efficient pooling layers\n"
                       "- Consider quantization or pruning\n"
                       )
        elif avg_latency > self.constraints.get('max_latency', 100):   
            feedback += ("ğŸŸ£ Need to reduce latency:\n"
                       "- Optimize convolution operations\n"
                       "- Reduce number of blocks in each stage\n"
                       "- Use depthwise separable convolutions\n"
                       "- Consider model quantization\n"
                       "- Reduce model size by removing redundant blocks\n")
        else:
            feedback += ("ğŸŸ¢ Balanced optimization suggestions:\n"
                       "- Explore new accuracy-efficiency tradeoffs\n"
                       "- Try mixing different convolution types\n"
                       "- Optimize channel distribution across stages\n")
         # --- ç¬¬å››éƒ¨åˆ†ï¼š çº¦æŸæé†’ ---    
        # æ·»åŠ ç¡¬ä»¶çº¦æŸæé†’
        feedback += ("\nâš ï¸ Hardware constraints reminder:\n"
                    f"- SRAM < {float(self.constraints['max_sram'])/1024:.0f}KB\n"
                    f"- MACs âˆˆ [{float(self.constraints['min_macs'])/1e6:.0f}M,"
                    f"{float(self.constraints['max_macs'])/1e6:.0f}M]\n"
                    f"- Peak Memory < {float(self.constraints['max_peak_memory'])/1e6:.0f}MB\n"
                    F"- Latency < {self.constraints.get('max_latency', 100):.0f} ms\n")
        
        return feedback
    
    def get_front(self) -> List[CandidateModel]:
        """
        è·å–å½“å‰Paretoå‰æ²¿(æŒ‰å‡†ç¡®ç‡é™åºæ’åº)
        
        è¿”å›:
            List[CandidateModel]: æ’åºåçš„å‰æ²¿è§£åˆ—è¡¨
        """
        # return sorted(self.front, 
        #              key=lambda x: (-x.metrics['accuracy'], 
        #                            x.metrics['macs'], 
        #                            x.metrics['params']))
        return sorted(self.front, 
              key=lambda x: (-x.accuracy, 
                             x.macs, 
                             x.params))

    

    def is_best(self, candidate: CandidateModel) -> bool:
        """
        æ£€æŸ¥ç»™å®šå€™é€‰æ˜¯å¦å½“å‰æœ€ä½³å‡†ç¡®ç‡æ¨¡å‹
        
        å‚æ•°:
            candidate: è¦æ£€æŸ¥çš„å€™é€‰æ¨¡å‹
            
        è¿”å›:
            bool: æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
        """
        return candidate == self.best_accuracy_model
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–Paretoå‰æ²¿çš„ç»Ÿè®¡ä¿¡æ¯
        
        è¿”å›:
            dict: åŒ…å«å„ç§ç»Ÿè®¡æŒ‡æ ‡çš„å­—å…¸
        """
        if not self.front:
            return {}
            
        # accuracies = [m.metrics['accuracy'] for m in self.front]
        # macs_list = [m.metrics['macs'] for m in self.front]
        # params_list = [m.metrics['params'] for m in self.front]

        accuracies = [m.accuracy for m in self.front]
        macs_list = [m.macs for m in self.front]
        params_list = [m.params for m in self.front]

        
        return {
            'size': len(self.front),
            'accuracy': {
                'max': max(accuracies),
                'min': min(accuracies),
                'mean': np.mean(accuracies),
                'std': np.std(accuracies)
            },
            'macs': {
                'max': max(macs_list),
                'min': min(macs_list),
                'mean': np.mean(macs_list),
                'std': np.std(macs_list)
            },
            'params': {
                'max': max(params_list),
                'min': min(params_list),
                'mean': np.mean(params_list),
                'std': np.std(params_list)
            }
        }

    def reset(self):
        """é‡ç½®Paretoå‰æ²¿å’Œæœç´¢çŠ¶æ€"""
        self.front = []
        self.best_accuracy_model = None
        self.best_accuracy = -1
        self.history = []